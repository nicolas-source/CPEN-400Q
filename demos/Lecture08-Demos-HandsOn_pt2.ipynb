{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ecc2235-07c3-4098-8bb1-cd170f86e5c5",
   "metadata": {},
   "source": [
    "# Demos: Lecture 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65812e14-324c-435f-ade6-362f6a9ff4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from lecture08_helpers import compute_accuracy\n",
    "from lecture08_helpers import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loads the training and testing data for you\n",
    "train_X = np.load(\"data/l8_train_X.npy\")\n",
    "train_y = np.load(\"data/l8_train_y.npy\")\n",
    "test_X = np.load(\"data/l8_test_X.npy\")\n",
    "test_y = np.load(\"data/l8_test_y.npy\")\n",
    "\n",
    "train_X = np.array(train_X, requires_grad=False)\n",
    "train_y = np.array(train_y, requires_grad=False)\n",
    "test_X = np.array(test_X, requires_grad=False)\n",
    "test_y = np.array(test_y, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.07161386, -0.22872007,  0.88470143, -0.10581928],\n        [ 1.64567103, -0.66481804, -0.57328593,  0.07178712],\n        [ 0.26837931,  0.42790794,  0.15068389, -0.45816579],\n        [ 0.23364672,  0.32846986,  0.6326616 , -0.09151491],\n        [-1.05684875, -1.42349957, -1.3374081 ,  1.93054905],\n        [-0.64311332, -2.00718505, -1.60691971,  1.43026965],\n        [ 0.13988981,  0.28099617,  0.50405069, -0.44432248],\n        [ 0.05787516,  0.09546232,  1.28959618, -0.14956287],\n        [-0.42451288,  0.00777202,  0.83388789, -0.23143627],\n        [ 2.15115809,  0.02331367, -0.83677661,  0.59475188],\n        [ 2.38297868, -1.03423083, -0.66092546,  0.68480826],\n        [ 1.95689934, -0.60490362, -0.8247449 , -0.00755088],\n        [-0.51139536, -0.1408783 , -0.29199464, -0.09000482],\n        [-0.61007558, -2.01992869, -1.49499303,  1.90725233],\n        [ 1.88651323, -0.70172563, -0.54178926,  0.28770913],\n        [ 0.47585128,  0.4080172 ,  0.01257563, -0.14044039],\n        [-0.5143055 , -1.03751845, -1.27556374,  1.54726928],\n        [ 2.08588783, -0.89500879, -1.02836716,  0.32759538],\n        [ 0.38887878,  0.48568269,  0.23482376, -0.14717955],\n        [-1.28201385, -1.74837971, -1.16734096,  1.95234288],\n        [ 1.92703718, -0.64785521, -0.32767537,  0.89906089],\n        [-0.69192357, -1.92965718, -1.75235649,  1.90982797],\n        [ 1.19544338, -0.62386218, -0.60968516, -0.10546999],\n        [ 0.62243795,  0.0970107 ,  0.41501119,  0.12895509],\n        [ 0.09521039, -0.02572425,  0.21108246, -0.07145817],\n        [-0.02280704,  0.20118728,  0.54449577, -0.84614546],\n        [-0.12711453, -0.15579507,  0.4903614 , -0.48130691],\n        [-0.17364775, -0.15983536,  0.0882144 ,  0.01074919],\n        [-1.22690569, -1.2550638 , -0.97486657,  1.66321592],\n        [-0.46218481,  0.81401419,  0.1809002 , -0.4291516 ],\n        [ 1.83053273, -0.20749595, -0.28371946, -0.12061734],\n        [-1.26453952, -1.49440832, -1.12864661,  1.80406456],\n        [-1.17507852, -1.25494588, -0.99818376,  1.76867666],\n        [-1.48407355, -1.05878584, -1.55640528,  1.63507614],\n        [ 1.94312769, -1.0289288 , -0.57768804,  0.15151588],\n        [ 0.20703644,  0.40606702,  0.12999374,  0.17149224],\n        [-0.94464439, -1.21887534, -0.9806999 ,  2.20846684],\n        [ 2.17107237, -0.6690854 , -0.91132546,  0.22258746],\n        [-0.774864  , -1.8920977 , -1.025828  ,  1.46864307],\n        [ 1.60141869,  0.43956814, -0.58256841,  0.49817361],\n        [-1.52492964, -1.39719588, -0.85408926,  1.72426919],\n        [-0.45227555,  0.23236524,  0.8241167 ,  0.02890293],\n        [ 0.5110872 , -0.01664523,  0.92810599, -0.16885533],\n        [-1.15938411, -1.19108019, -1.33144069,  1.46450453],\n        [-1.16333175, -1.70045152, -1.19780563,  1.61611838],\n        [ 0.56297203,  0.08692899,  1.14958082, -0.09909477],\n        [ 1.86671724, -0.80547652, -0.73786036,  0.99708209],\n        [-1.49065882, -1.81326296, -1.01608834,  2.02086156],\n        [-1.09953314, -1.70676539, -0.58961773,  1.63478568],\n        [ 1.70659588, -1.02739668, -0.88746166,  0.36700138],\n        [ 1.98132706, -0.87210913, -0.52239302,  0.26888068],\n        [ 1.7973304 , -0.7629594 , -0.47408134, -0.08283167],\n        [ 1.62146585, -0.89484357, -0.67353102,  0.21917219],\n        [ 2.02109855, -0.46923982, -0.16720192,  0.55392231],\n        [ 2.13766664, -0.32188401, -1.3807471 ,  0.29554881],\n        [-0.70560376, -1.34573435, -1.1336461 ,  1.478987  ],\n        [-0.0746666 ,  0.06494707,  0.63972834, -0.09333582],\n        [-1.2586682 , -1.12515908, -1.22388337,  1.53308056],\n        [ 1.74756553, -0.2948207 , -0.87999491,  0.87285002],\n        [-1.09787142, -1.4832972 , -1.13328012,  1.3670349 ]], requires_grad=False)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "6e121ef6-0c3f-4e61-aec2-0ec7b1c360b3",
   "metadata": {},
   "source": [
    "## Hands-on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b903c3-b99c-43d4-818c-42c3b789e7e3",
   "metadata": {},
   "source": [
    "Design your own VQC to classify this data! Try to beat my record of 93.3\\% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "NUM_WIRES = 4\n",
    "NUM_PARAMS = 3\n",
    "NUM_LAYERS = 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "weights = np.random.normal(size=(NUM_WIRES*NUM_LAYERS, NUM_PARAMS))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.1049548 ,  1.66701038, -1.09682379],\n        [-0.31850905,  0.20698853,  0.00185679],\n        [ 1.45003148, -1.57998593,  0.43237273],\n        [ 1.40336851, -0.64938225,  1.62909963],\n        [-0.85178059, -0.29882222, -1.24790773],\n        [-0.92005539,  0.4103234 ,  1.18440713],\n        [ 0.62437989,  0.499178  ,  0.80402053],\n        [-0.30086374, -0.16820966, -1.22348312]], requires_grad=True)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.1049548 ,  1.66701038, -1.09682379], requires_grad=True)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4fafcc0-d817-4a97-8887-176c08601e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit', wires=NUM_WIRES)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def vqc_model(data, weights):\n",
    "    # YOUR CODE HERE\n",
    "    # Design an ansatz for this data: choose how the data is encoded\n",
    "    # and the gates that the weights are input into.\n",
    "    qml.AngleEmbedding(data, wires=[0,1,2,3])\n",
    "    qml.Rot(*weights[0], wires=0)\n",
    "    qml.Rot(*weights[1], wires=1)\n",
    "    qml.Rot(*weights[2], wires=2)\n",
    "    qml.Rot(*weights[3], wires=3)\n",
    "\n",
    "    qml.CNOT(wires=[0,1])\n",
    "    qml.CNOT(wires=[1,2])\n",
    "    qml.CNOT(wires=[2,3])\n",
    "    qml.CNOT(wires=[3,0])\n",
    "\n",
    "    qml.Rot(*weights[4], wires=0)\n",
    "    qml.Rot(*weights[5], wires=1)\n",
    "    qml.Rot(*weights[6], wires=2)\n",
    "    qml.Rot(*weights[7], wires=3)\n",
    "\n",
    "    qml.CNOT(wires=[0,1])\n",
    "    qml.CNOT(wires=[1,2])\n",
    "    qml.CNOT(wires=[2,3])\n",
    "    qml.CNOT(wires=[3,0])\n",
    "\n",
    "    return qml.expval(qml.PauliX(0), qml.PauliX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "0: ──RX(-0.77)──Rot(0.10,1.67,-1.10)─╭●───────╭X──Rot(-0.85,-0.30,-1.25)─╭●───────╭X─┤  <X>\n",
      "1: ──RX(-1.89)──Rot(-0.32,0.21,0.00)─╰X─╭●────│───Rot(-0.92,0.41,1.18)───╰X─╭●────│──┤  <X>\n",
      "2: ──RX(-1.03)──Rot(1.45,-1.58,0.43)────╰X─╭●─│───Rot(0.62,0.50,0.80)───────╰X─╭●─│──┤     \n",
      "3: ──RX(1.47)───Rot(1.40,-0.65,1.63)───────╰X─╰●──Rot(-0.30,-0.17,-1.22)───────╰X─╰●─┤     \n"
     ]
    }
   ],
   "source": [
    "print(qml.draw(vqc_model, expansion_strategy=\"device\")(train_X[0], weights))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ae3951a-6052-47ad-9f9a-afbe3462ca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(weights):\n",
    "    # YOUR CODE HERE\n",
    "    # Design a new loss function, or adapt the helper function\n",
    "\n",
    "    loss_sum = 0.0\n",
    "\n",
    "    for idx in range(train_X.shape[0]):\n",
    "        point = train_X[idx]\n",
    "        true_expval = train_y[idx]\n",
    "\n",
    "        estimated_expval = vqc_model(point, weights)\n",
    "        loss_sum += (estimated_expval - true_expval) ** 2\n",
    "\n",
    "    return loss_sum / train_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "204d4adf-035d-448c-8b24-950e0ff9ca77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n",
      "(expval(PauliX(wires=[0])), expval(PauliX(wires=[1])))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Grad only applies to real scalar-output functions. Try jacobian, elementwise_grad or holomorphic_grad.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m loss_track \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m it \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_its):\n\u001B[0;32m---> 10\u001B[0m     weights, _loss \u001B[38;5;241m=\u001B[39m \u001B[43mopt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep_and_cost\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m it \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m5\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     12\u001B[0m         our_preds \u001B[38;5;241m=\u001B[39m make_predictions(train_X, vqc_model, weights)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PennyLane/lib/python3.9/site-packages/pennylane/optimize/gradient_descent.py:59\u001B[0m, in \u001B[0;36mGradientDescentOptimizer.step_and_cost\u001B[0;34m(self, objective_fn, grad_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep_and_cost\u001B[39m(\u001B[38;5;28mself\u001B[39m, objective_fn, \u001B[38;5;241m*\u001B[39margs, grad_fn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;124;03m\"\"\"Update trainable arguments with one step of the optimizer and return the corresponding\u001B[39;00m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;124;03m    objective function value prior to the step.\u001B[39;00m\n\u001B[1;32m     42\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;124;03m        If single arg is provided, list [array] is replaced by array.\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 59\u001B[0m     g, forward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m     new_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_grad(g, args)\n\u001B[1;32m     62\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m forward \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PennyLane/lib/python3.9/site-packages/pennylane/optimize/gradient_descent.py:117\u001B[0m, in \u001B[0;36mGradientDescentOptimizer.compute_grad\u001B[0;34m(objective_fn, args, kwargs, grad_fn)\u001B[0m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Compute gradient of the objective function at the given point and return it along with\u001B[39;00m\n\u001B[1;32m    100\u001B[0m \u001B[38;5;124;03mthe objective function forward pass (if available).\u001B[39;00m\n\u001B[1;32m    101\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;124;03m    will not be evaluted and instead ``None`` will be returned.\u001B[39;00m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    116\u001B[0m g \u001B[38;5;241m=\u001B[39m get_gradient(objective_fn) \u001B[38;5;28;01mif\u001B[39;00m grad_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m grad_fn\n\u001B[0;32m--> 117\u001B[0m grad \u001B[38;5;241m=\u001B[39m \u001B[43mg\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m forward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(g, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mforward\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    120\u001B[0m num_trainable_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(\u001B[38;5;28mgetattr\u001B[39m(arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequires_grad\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m args)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PennyLane/lib/python3.9/site-packages/pennylane/_grad.py:115\u001B[0m, in \u001B[0;36mgrad.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fun(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    113\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ()\n\u001B[0;32m--> 115\u001B[0m grad_value, ans \u001B[38;5;241m=\u001B[39m \u001B[43mgrad_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward \u001B[38;5;241m=\u001B[39m ans\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m grad_value\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PennyLane/lib/python3.9/site-packages/autograd/wrap_util.py:20\u001B[0m, in \u001B[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     19\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(args[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m argnum)\n\u001B[0;32m---> 20\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43munary_operator\u001B[49m\u001B[43m(\u001B[49m\u001B[43munary_f\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnary_op_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnary_op_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PennyLane/lib/python3.9/site-packages/pennylane/_grad.py:136\u001B[0m, in \u001B[0;36mgrad._grad_with_forward\u001B[0;34m(fun, x)\u001B[0m\n\u001B[1;32m    133\u001B[0m vjp, ans \u001B[38;5;241m=\u001B[39m _make_vjp(fun, x)\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m vspace(ans)\u001B[38;5;241m.\u001B[39msize \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 136\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    137\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGrad only applies to real scalar-output functions. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    138\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTry jacobian, elementwise_grad or holomorphic_grad.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    139\u001B[0m     )\n\u001B[1;32m    141\u001B[0m grad_value \u001B[38;5;241m=\u001B[39m vjp(vspace(ans)\u001B[38;5;241m.\u001B[39mones())\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m grad_value, ans\n",
      "\u001B[0;31mTypeError\u001B[0m: Grad only applies to real scalar-output functions. Try jacobian, elementwise_grad or holomorphic_grad."
     ]
    }
   ],
   "source": [
    "# Set up initial parameters, and write an optimization loop to train your model.\n",
    "\n",
    "opt = qml.GradientDescentOptimizer(stepsize=0.1)\n",
    "\n",
    "n_its = 100\n",
    "\n",
    "loss_track = []\n",
    "\n",
    "for it in range(n_its):\n",
    "    weights, _loss = opt.step_and_cost(loss, weights)\n",
    "    if it % 5 == 0:\n",
    "        our_preds = make_predictions(train_X, vqc_model, weights)\n",
    "        print(f\"Loss at iteration {it} = {_loss}  Accuracy = {compute_accuracy(our_preds, train_y)}\")\n",
    "    loss_track.append(_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13258f8e-aa83-46e4-92c3-c7ce161611db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_predictions(data, model, weights):\n",
    "#     # YOUR CODE HERE\n",
    "#     # Modify the make_predictions function based on how you set up your classifier.\n",
    "#\n",
    "#     return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e8d73-2e65-448e-b801-0d7126573f41",
   "metadata": {},
   "source": [
    "After training, you can use the code below to evaluate the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5390a0a-fb72-4ded-8d6f-641f9f9f7a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_training_predictions = make_predictions(train_X, vqc_model, weights)\n",
    "my_testing_predictions = make_predictions(test_X, vqc_model, weights)\n",
    "                                          \n",
    "training_accuracy = compute_accuracy(my_training_predictions, train_y)\n",
    "testing_accuracy = compute_accuracy(my_testing_predictions, test_y)\n",
    "\n",
    "print(f\"Training accuracy = {training_accuracy}\")\n",
    "print(f\"Testing accuracy = {testing_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c4fcd3-c5ea-4b28-be0c-d8616496b0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pennylane",
   "language": "python",
   "display_name": "PennyLane"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
